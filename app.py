import streamlit as st
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import time
import requests

# ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆå–å¾—
def get_usd_to_jpy():
    url = "https://api.exchangerate.host/latest?base=USD&symbols=JPY"
    try:
        response = requests.get(url)
        data = response.json()
        return data["rates"]["JPY"]
    except:
        return 152.80

# ã‚¹ã‚³ã‚¢è¨ˆç®—
def calculate_scores(roe_dict, per_dict, roe_weight=0.6):
    per_weight = 1.0 - roe_weight
    df = pd.DataFrame({
        "Ticker": list(roe_dict.keys()),
        "ROE": list(roe_dict.values()),
        "PER": list(per_dict.values())
    })
    scaler = MinMaxScaler()
    df[["ROE_norm", "PER_norm"]] = scaler.fit_transform(df[["ROE", "PER"]])
    df["Score"] = df["ROE_norm"] * roe_weight - df["PER_norm"] * per_weight
    df["Weight"] = df["Score"] / df["Score"].sum()
    df = df.dropna(subset=["Score", "Weight"])
    return df

# éŠ˜æŸ„åˆ†å‰²
def chunk_list(lst, chunk_size):
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]

# Streamlit UI
st.set_page_config(page_title="åˆæœŸè³¼å…¥ãƒ¢ãƒ‡ãƒ«ï¼ˆCSVå¯¾å¿œï¼‰", layout="wide")
st.title("ğŸ“ˆ åˆæœŸè³¼å…¥ãƒ¢ãƒ‡ãƒ«ï¼šç”ŸæˆAIï¼‹åŠå°ä½“æ ªï¼ˆCSVå½¢å¼ã§ä¿å­˜ï¼‰")

initial_yen = st.number_input("åˆæœŸæŠ•è³‡é¡ï¼ˆå††ï¼‰", value=300000)
roe_weight = st.slider("ROEã®é‡ã¿", 0.0, 1.0, 0.6)

usd_to_jpy = get_usd_to_jpy()
st.write(f"ğŸ“ˆ ç¾åœ¨ã®ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼ˆUSDâ†’JPYï¼‰: {usd_to_jpy:.2f} å††")
initial_usd = initial_yen / usd_to_jpy

# éŠ˜æŸ„æƒ…å ±
tickers_info = {
    "NVDA": "GPUãƒ»AIåŠå°ä½“ã®è¨­è¨ˆãƒ»é–‹ç™º", "AMD": "CPUãƒ»GPUã®è¨­è¨ˆã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å‘ã‘è£½å“",
    "AVGO": "é€šä¿¡ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å‘ã‘åŠå°ä½“", "ASML": "EUVéœ²å…‰è£…ç½®ã®ä¸–ç•Œæœ€å¤§æ‰‹",
    "SMCI": "AIã‚µãƒ¼ãƒãƒ¼ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å‘ã‘ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢", "INTC": "CPUãƒ»åŠå°ä½“è£½é€ ï¼ˆIDMï¼‰",
    "QCOM": "ã‚¹ãƒãƒ›å‘ã‘SoCãƒ»5Gãƒãƒƒãƒ—", "TXN": "ã‚¢ãƒŠãƒ­ã‚°åŠå°ä½“ãƒ»ç”£æ¥­ç”¨IC",
    "MU": "ãƒ¡ãƒ¢ãƒªï¼ˆDRAM/NANDï¼‰è£½é€ ", "MRVL": "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å‘ã‘åŠå°ä½“",
    "TSM": "ä¸–ç•Œæœ€å¤§ã®åŠå°ä½“å—è¨—è£½é€ ï¼ˆãƒ•ã‚¡ã‚¦ãƒ³ãƒ‰ãƒªï¼‰", "AMAT": "åŠå°ä½“è£½é€ è£…ç½®ï¼ˆæˆè†œãƒ»ã‚¨ãƒƒãƒãƒ³ã‚°ï¼‰",
    "LRCX": "åŠå°ä½“è£½é€ è£…ç½®ï¼ˆæ´—æµ„ãƒ»ã‚¨ãƒƒãƒãƒ³ã‚°ï¼‰", "KLAC": "åŠå°ä½“æ¤œæŸ»è£…ç½®",
    "NXPI": "è»Šè¼‰ãƒ»IoTå‘ã‘åŠå°ä½“", "ADI": "ã‚¢ãƒŠãƒ­ã‚°ãƒ»ãƒŸãƒƒã‚¯ã‚¹ãƒ‰ã‚·ã‚°ãƒŠãƒ«IC",
    "ON": "ãƒ‘ãƒ¯ãƒ¼åŠå°ä½“ãƒ»è»Šè¼‰å‘ã‘IC", "GFS": "å…ˆç«¯ãƒ•ã‚¡ã‚¦ãƒ³ãƒ‰ãƒªï¼ˆç±³å›½æ‹ ç‚¹ï¼‰",
    "AEHR": "ã‚·ãƒªã‚³ãƒ³ã‚«ãƒ¼ãƒã‚¤ãƒ‰å‘ã‘ãƒ†ã‚¹ãƒˆè£…ç½®", "UCTT": "åŠå°ä½“è£½é€ è£…ç½®ã®éƒ¨æãƒ»çµ„ç«‹"
}
tickers = list(tickers_info.keys())

# ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆåˆ†å‰²ï¼‰
roe_data = {}
per_data = {}
prices = {}
progress_bar = st.progress(0)
chunk_size = 5
total_chunks = len(list(chunk_list(tickers, chunk_size)))
chunk_index = 0

for group in chunk_list(tickers, chunk_size):
    for ticker in group:
        stock = yf.Ticker(ticker)
        try:
            prices[ticker] = stock.history(period="1d")["Close"].iloc[-1]
        except:
            prices[ticker] = None
        try:
            info = stock.info
            roe = info.get("returnOnEquity")
            per = info.get("trailingPE")
            roe_data[ticker] = roe * 100 if roe else 0
            per_data[ticker] = per if per else 100
        except:
            roe_data[ticker] = 0
            per_data[ticker] = 100
    chunk_index += 1
    progress_bar.progress(chunk_index / total_chunks)
    time.sleep(10)

# ã‚¹ã‚³ã‚¢è¨ˆç®—
df = calculate_scores(roe_data, per_data, roe_weight)
df["Price"] = df["Ticker"].map(prices)
df["Business"] = df["Ticker"].map(tickers_info)
df = df.dropna(subset=["Price"])
df_sorted = df.sort_values(by="Score", ascending=False).copy()

# å¿…ãš5éŠ˜æŸ„è³¼å…¥
df_top5 = df_sorted.head(5).copy()
allocated_usd = initial_usd / 5
df_top5["Shares"] = (allocated_usd / df_top5["Price"]).astype(int)
df_top5["Used_USD"] = df_top5["Shares"] * df_top5["Price"]
df_top5["Used_JPY"] = df_top5["Used_USD"] * usd_to_jpy
total_invested_yen = df_top5["Used_JPY"].sum()

# é¸å®šç†ç”±ç”Ÿæˆ
df_top5["Reason"] = df_top5.apply(lambda row: f"{row['Ticker']}ã¯{row['Business']}ã‚’æ‰‹ãŒã‘ã¦ãŠã‚Šã€ROE {row['ROE']:.1f}%ã€PER {row['PER']:.1f}å€ã¨è²¡å‹™æŒ‡æ¨™ã‚‚å„ªç§€ã€‚ã‚¹ã‚³ã‚¢ä¸Šä½ã«ä½ç½®ã™ã‚‹ãŸã‚ã€åˆæœŸè³¼å…¥å¯¾è±¡ã«é¸å®šã—ã¾ã—ãŸã€‚", axis=1)

# è¡¨ç¤º
st.subheader("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå…¨éŠ˜æŸ„ï¼‰")
st.dataframe(df_sorted[["Ticker", "Business", "ROE", "PER", "Score"]])

st.subheader("ğŸ’° åˆæœŸè³¼å…¥å¯¾è±¡ï¼ˆå¿…ãš5éŠ˜æŸ„ï¼‰")
st.dataframe(df_top5[["Ticker", "Business", "Shares", "Price", "Used_USD", "Used_JPY", "Reason"]])
st.write(f"ğŸ§¾ åˆè¨ˆæŠ•è³‡é¡ï¼ˆå††ï¼‰: {total_invested_yen:,.0f} å††")
if total_invested_yen > initial_yen:
    st.warning(f"âš ï¸ åˆè¨ˆæŠ•è³‡é¡ãŒäºˆç®—ã‚’ {total_invested_yen - initial_yen:,.0f} å††ã‚ªãƒ¼ãƒãƒ¼ã—ã¦ã„ã¾ã™")

# CSVä¿å­˜ï¼ˆæœˆæ¬¡ãƒ¢ãƒ‡ãƒ«äº’æ›ï¼‰
st.subheader("ğŸ“¥ æœˆæ¬¡ãƒ¢ãƒ‡ãƒ«ç”¨CSVä¿å­˜")
df_top5["PurchasePriceUSD"] = df_top5["Price"]
df_top5["PurchaseDate"] = pd.Timestamp.today().strftime("%Y-%m-%d")
df_top5["ROE"] = df_top5["Ticker"].map(roe_data)
df_top5["PER"] = df_top5["Ticker"].map(per_data)
df_top5["Score"] = df_top5["Ticker"].map(df.set_index("Ticker")["Score"])
df_top5["PurchaseRate"] = usd_to_jpy
portfolio_df = df_top5[["Ticker", "Shares", "PurchasePriceUSD", "PurchaseDate", "ROE", "PER", "Score", "PurchaseRate"]]
csv = portfolio_df.to_csv(index=False).encode("utf-8")
st.download_button("ğŸ“„ portfolio.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="portfolio.csv", mime="text/csv")

# ã‚°ãƒ©ãƒ•
st.subheader("ğŸ“Š è³‡é‡‘é…åˆ†ã‚°ãƒ©ãƒ•ï¼ˆå††æ›ç®—ï¼‰")
labels = df_top5["Ticker"]
sizes = df_top5["Used_JPY"]
fig, ax = plt.subplots()
ax.pie(sizes, labels=labels, autopct="%1.1f%%", startangle=90)
ax.axis("equal")
st.pyplot(fig)
